{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e330663",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with Python\n",
    "\n",
    "The following tutorial and the associated examples are based on \"NLTK Sentiment Analysis Tutorial for Beginners\" : https://www.datacamp.com/tutorial/text-analytics-beginners-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ff52f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/dbabichenko/opt/anaconda3/lib/python3.9/site-packages (3.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/dbabichenko/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.7.9)\r\n",
      "Requirement already satisfied: joblib in /Users/dbabichenko/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/dbabichenko/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.1)\r\n",
      "Requirement already satisfied: click in /Users/dbabichenko/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\r\n"
     ]
    }
   ],
   "source": [
    "# If nltk is not installed, install it\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b955c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a18a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  Positive\n",
       "0  This is a one of the best apps acording to a b...         1\n",
       "1  This is a pretty good version of the game for ...         1\n",
       "2  this is a really cool game. there are a bunch ...         1\n",
       "3  This is a silly game and can be frustrating, b...         1\n",
       "4  This is a terrific game on any pad. Hrs of fun...         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('amazon_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732753c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9014b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df.sample(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a8384",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "The following function preprocesses text through **tokenization**, **stop word removal**, and **lemmatization**.\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "**Tokenization** in Natural Language Processing (NLP) is the process of breaking down text into smaller units called tokens. These tokens can be words, phrases, or even characters, depending on the level of granularity needed for the task.\n",
    "\n",
    "**Steps in Tokenization:**\n",
    "* Text Segmentation: The text is split based on spaces, punctuation, or other predefined rules. For example, the sentence \"I love NLP!\" might be tokenized into [\"I\", \"love\", \"NLP\", \"!\"].\n",
    "* Handling Special Cases: Tokenizers also manage edge cases like contractions (e.g., \"don't\" into [\"do\", \"n't\"]), hyphenated words, and abbreviations.\n",
    "* Normalization: Tokens might be converted to lowercase, numbers might be replaced with a special token, or other forms of text normalization might be applied.\n",
    "\n",
    "**Types of Tokenization:**\n",
    "* Word Tokenization: Splits text into words. Example: \"Tokenization is fun\" → [\"Tokenization\", \"is\", \"fun\"].\n",
    "* Subword Tokenization: Breaks down words into meaningful subword units, useful in handling unknown words. Example: \"unhappiness\" → [\"un\", \"happiness\"].\n",
    "* Character Tokenization: Splits text into individual characters. Example: \"cat\" → [\"c\", \"a\", \"t\"].\n",
    "\n",
    "### Stop Word Removal\n",
    "Stop word removal is a process in Natural Language Processing (NLP) where common words that carry little meaningful information are filtered out from the text. These words, known as \"stop words,\" include terms like \"the,\" \"is,\" \"in,\" \"and,\" etc.\n",
    "\n",
    "Stop words are typically removed because they appear frequently in text but don't contribute much to the understanding of the content. By removing them, the focus is placed on more significant words that carry the essence of the text.\n",
    "\n",
    "For the sentence \"The cat is sitting on the mat,\" after stop word removal, it might become \"cat sitting mat.\"\n",
    "\n",
    "**Benefits:**\n",
    "* Reduces Text Size: It helps in reducing the dimensionality of the text, making processing more efficient.\n",
    "* Improves Model Performance: By eliminating irrelevant words, models can focus on the words that actually contribute to the task, potentially improving performance in tasks like text classification, search engines, or sentiment analysis.\n",
    "\n",
    "### Lemmatization\n",
    "Lemmatization is a process in Natural Language Processing (NLP) that reduces words to their base or root form, known as the \"lemma.\" Unlike stemming, which just cuts off word endings, lemmatization considers the word's meaning and context to transform it into a valid dictionary form.\n",
    "\n",
    "**How It Works:**\n",
    "* Context-Aware: Lemmatization uses the context of the word (like its part of speech) to accurately reduce it to its lemma. For example, \"running\" becomes \"run,\" and \"better\" becomes \"good.\"\n",
    "* Morphological Analysis: It analyzes the structure and morphology of the word to ensure that the lemma is a valid word in the language.\n",
    "\n",
    "**Example:**\n",
    "* \"running\" → \"run\"\n",
    "* \"was\" → \"be\"\n",
    "* \"mice\" → \"mouse\"\n",
    "\n",
    "**Benefits:**\n",
    "Lemmatization helps in reducing inflectional forms and grouping similar words together, which improves the accuracy of text processing tasks like information retrieval, text mining, and sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196141b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocess_text function\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "\n",
    "    # Join the tokens back into a string\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function df\n",
    "\n",
    "df_temp['reviewTextProcessed'] = df_temp['reviewText'].apply(preprocess_text)\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8768be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize NLTK sentiment analyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# create get_sentiment function\n",
    "\n",
    "def get_sentiment(text):\n",
    "\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# apply get_sentiment function\n",
    "\n",
    "df['sentiment'] = df['reviewText'].apply(get_sentiment)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbebda8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
