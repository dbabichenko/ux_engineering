{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12f4a84",
   "metadata": {},
   "source": [
    "## Unsupervised Thematic Analysis with K-Means \n",
    "__(on interview utterances)__\n",
    "1. Load transcripts (expects heritageRoots-style JSON).\n",
    "2. Vectorize text with TF-IDF (unigrams + bigrams).\n",
    "3. Choose k via silhouette score.\n",
    "4. Fit KMeans and interpret clusters by top terms.\n",
    "5. Inspect sample quotes; \n",
    "6. (optional) visualize with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6efec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0fdea0",
   "metadata": {},
   "source": [
    "### Step 1: Load participant utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ea4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 120 participant utterances.\n"
     ]
    }
   ],
   "source": [
    "DATA = Path(\"data/heritageroots_ux_transcripts.json\")  # adjust path if needed\n",
    "with open(DATA, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw = json.load(f)\n",
    "\n",
    "rows = []\n",
    "for p in raw[\"participants\"]:\n",
    "    pid = p[\"id\"]\n",
    "    for t in p[\"transcript\"]:\n",
    "        if t[\"speaker\"] == \"Participant\":\n",
    "            rows.append({\"participant_id\": pid, \"time\": t[\"time\"], \"text\": t[\"text\"]})\n",
    "\n",
    "df = pd.DataBox = pd.DataFrame(rows)\n",
    "print(f\"Loaded {len(df)} participant utterances.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85fffbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:00:48]</td>\n",
       "      <td>The lighting and spatial sound immediately mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:01:20]</td>\n",
       "      <td>Teleportation is smooth, but I’d like a quick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:01:54]</td>\n",
       "      <td>The icons are intuitive but slightly small. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:02:16]</td>\n",
       "      <td>Picking up artifacts feels satisfying. However...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:03:08]</td>\n",
       "      <td>No lag, though the ambient sound loop is a lit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id        time  \\\n",
       "0            P01  [00:00:48]   \n",
       "1            P01  [00:01:20]   \n",
       "2            P01  [00:01:54]   \n",
       "3            P01  [00:02:16]   \n",
       "4            P01  [00:03:08]   \n",
       "\n",
       "                                                text  \n",
       "0  The lighting and spatial sound immediately mak...  \n",
       "1  Teleportation is smooth, but I’d like a quick ...  \n",
       "2  The icons are intuitive but slightly small. I ...  \n",
       "3  Picking up artifacts feels satisfying. However...  \n",
       "4  No lag, though the ambient sound loop is a lit...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdbbbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty or duplicate lines for cleanliness\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\").str.strip()\n",
    "df = df[df[\"text\"] != \"\"].drop_duplicates(subset=[\"participant_id\", \"time\", \"text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f36d763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:00:48]</td>\n",
       "      <td>The lighting and spatial sound immediately mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:01:20]</td>\n",
       "      <td>Teleportation is smooth, but I’d like a quick ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:01:54]</td>\n",
       "      <td>The icons are intuitive but slightly small. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:02:16]</td>\n",
       "      <td>Picking up artifacts feels satisfying. However...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01</td>\n",
       "      <td>[00:03:08]</td>\n",
       "      <td>No lag, though the ambient sound loop is a lit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id        time  \\\n",
       "0            P01  [00:00:48]   \n",
       "1            P01  [00:01:20]   \n",
       "2            P01  [00:01:54]   \n",
       "3            P01  [00:02:16]   \n",
       "4            P01  [00:03:08]   \n",
       "\n",
       "                                                text  \n",
       "0  The lighting and spatial sound immediately mak...  \n",
       "1  Teleportation is smooth, but I’d like a quick ...  \n",
       "2  The icons are intuitive but slightly small. I ...  \n",
       "3  Picking up artifacts feels satisfying. However...  \n",
       "4  No lag, though the ambient sound loop is a lit...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d9f212",
   "metadata": {},
   "source": [
    "### Step 2: TF-IDF vectorization (uni + bigrams)\n",
    "__Tune min_df/max_df to control noise.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d3cc6",
   "metadata": {},
   "source": [
    "## TF–IDF (Term Frequency–Inverse Document Frequency)\n",
    "\n",
    "### Purpose:\n",
    "*   TF–IDF is a way to measure how important a word is in a document, compared to how often it appears across all documents in a dataset.\n",
    "*\tIt’s widely used in text mining, NLP, and machine learning to turn words into numerical features.\n",
    "\n",
    "### Term Frequency (TF)\n",
    "*\tTF measures how often a word appears in a single document.\n",
    "*\tFormula: _TF(word,document) = Total words in the document / Number of times word appears_\n",
    "*\tExample: \n",
    "\t*\tIn “VR is immersive and VR is fun,”\n",
    "\t* TF(VR) = 2/6 = 0.33\n",
    "\n",
    "### Inverse Document Frequency (IDF)\n",
    "*\tIDF measures how unique or rare a word is across all documents.\n",
    "*\tCommon words (like “the” or “and”) get lower weight\n",
    "*\tFormula: IDF(word)=log(Number of documents containing the word / Total number of documents)\n",
    "*\tRare words get high IDF; frequent ones get low IDF.\n",
    "\n",
    "### Combine Them: TF × IDF\n",
    "*\tMultiply the two values to get the TF–IDF score.\n",
    "*\tWords that are frequent in one document but rare across the dataset get the highest scores.\n",
    "*\tExample: If “teleport” appears often only in VR usability interviews, it becomes a strong thematic indicator.\n",
    "\n",
    "### Why It’s Useful\n",
    "*\tReduces noise from common filler words.\n",
    "*\tHighlights topic-specific terms that distinguish documents.\n",
    "*\tUsed in:\n",
    "\t*\tKeyword extraction\n",
    "\t*\tThematic clustering (like k-means)\n",
    "\t*\tSearch and information retrieval\n",
    "\t*\tText classification and sentiment analysis\n",
    "*\tQuick Analogy\n",
    "\t*\tImagine each document is a conversation.\n",
    "\t*\tTF–IDF finds the words people say a lot in one conversation that others rarely mention — those are your unique themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ba267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape: (120, 130)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,          # ignore very rare terms; tweak as needed\n",
    "    max_df=0.85        # drop very common terms\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"text\"])\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "print(f\"TF-IDF matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "584eb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pick k with silhouette score (coarse elbow-style scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd8f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=2   silhouette=0.3412\n",
      "k=3   silhouette=0.5044\n",
      "k=4   silhouette=0.6683\n",
      "k=5   silhouette=0.8386\n",
      "k=6   silhouette=1.0000\n",
      "k=7   silhouette=1.0000\n",
      "k=8   silhouette=1.0000\n",
      "\n",
      "Chosen k = 6 (max silhouette)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (7). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def choose_k(X, k_values=(2,3,4,5,6,7,8)):\n",
    "    scores = {}\n",
    "    for k in k_values:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "        labels = km.fit_predict(X)\n",
    "        score = silhouette_score(X, labels, metric=\"cosine\")\n",
    "        scores[k] = score\n",
    "        print(f\"k={k:<2}  silhouette={score:.4f}\")\n",
    "    best_k = max(scores, key=scores.get)\n",
    "    print(f\"\\nChosen k = {best_k} (max silhouette)\")\n",
    "    return best_k, scores\n",
    "\n",
    "best_k, scores = choose_k(X, k_values=range(2,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e060e20",
   "metadata": {},
   "source": [
    "### Fit KMeans with chosen k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ab8e3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=\"auto\")\n",
    "labels = kmeans.fit_predict(X)\n",
    "df[\"cluster\"] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c723a",
   "metadata": {},
   "source": [
    "### Inspect clusters: top terms + sample utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9350366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cluster 0 : top 12 terms ===\n",
      "flat, staying, prefer menus, icons, icons intuitive, menus curve, menus, slightly, slightly small, small prefer, curve view, curve\n",
      "\n",
      "=== Cluster 1 : top 12 terms ===\n",
      "wasn sure, immersive, noticed floating, make feel, make, wasn, lighting spatial, lighting, immersive noticed, immediately make, panels wasn, immediately\n",
      "\n",
      "=== Cluster 2 : top 12 terms ===\n",
      "preview, smooth like, fade, fade helps, quick preview, quick, preview ll, land fade, help, help directionally, helps, helps maybe\n",
      "\n",
      "=== Cluster 3 : top 12 terms ===\n",
      "small vibration, artifacts feels, feedback grabbed, feedback, satisfying expected, satisfying, feels satisfying, expected haptic, expected, maybe small, feels, artifacts\n",
      "\n",
      "=== Cluster 4 : top 12 terms ===\n",
      "intuitive overall, overlay launch, launch, interaction, interaction cues, cues maybe, cues, overlay, overall just, just, just tweak, pretty intuitive\n",
      "\n",
      "=== Cluster 5 : top 12 terms ===\n",
      "little short, sound loop, repetition, lag ambient, ambient, ambient sound, lag, little, repetition minutes, short, short noticed, loop\n"
     ]
    }
   ],
   "source": [
    "def top_terms_per_cluster(kmeans, terms, topn=12):\n",
    "    centers = kmeans.cluster_centers_\n",
    "    for k in range(centers.shape[0]):\n",
    "        idx = np.argsort(centers[k])[::-1][:topn]\n",
    "        print(f\"\\n=== Cluster {k} : top {topn} terms ===\")\n",
    "        print(\", \".join(terms[idx]))\n",
    "\n",
    "top_terms_per_cluster(kmeans, terms, topn=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83f9b4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample quotes from Cluster 0 ---\n",
      "[P01 [00:01:54]] The icons are intuitive but slightly small. I prefer when menus curve around my view instead of staying flat in front of me.\n",
      "[P18 [00:01:56]] The icons are intuitive but slightly small. I prefer when menus curve around my view instead of staying flat in front of me.\n",
      "[P16 [00:01:38]] The icons are intuitive but slightly small. I prefer when menus curve around my view instead of staying flat in front of me.\n",
      "\n",
      "--- Sample quotes from Cluster 1 ---\n",
      "[P01 [00:00:48]] The lighting and spatial sound immediately make it feel immersive. I noticed the floating panels, but wasn’t sure which gesture activates them.\n",
      "[P18 [00:00:43]] The lighting and spatial sound immediately make it feel immersive. I noticed the floating panels, but wasn’t sure which gesture activates them.\n",
      "[P16 [00:00:46]] The lighting and spatial sound immediately make it feel immersive. I noticed the floating panels, but wasn’t sure which gesture activates them.\n",
      "\n",
      "--- Sample quotes from Cluster 2 ---\n",
      "[P01 [00:01:20]] Teleportation is smooth, but I’d like a quick preview of where I’ll land. The fade helps, but maybe a clearer arrow would help directionally.\n",
      "[P18 [00:01:16]] Teleportation is smooth, but I’d like a quick preview of where I’ll land. The fade helps, but maybe a clearer arrow would help directionally.\n",
      "[P16 [00:01:25]] Teleportation is smooth, but I’d like a quick preview of where I’ll land. The fade helps, but maybe a clearer arrow would help directionally.\n",
      "\n",
      "--- Sample quotes from Cluster 3 ---\n",
      "[P01 [00:02:16]] Picking up artifacts feels satisfying. However, I expected some haptic feedback when I grabbed something, maybe a small vibration.\n",
      "[P18 [00:02:29]] Picking up artifacts feels satisfying. However, I expected some haptic feedback when I grabbed something, maybe a small vibration.\n",
      "[P16 [00:02:42]] Picking up artifacts feels satisfying. However, I expected some haptic feedback when I grabbed something, maybe a small vibration.\n",
      "\n",
      "--- Sample quotes from Cluster 4 ---\n",
      "[P01 [00:03:54]] Pretty intuitive overall. I’d just tweak interaction cues and maybe add a tutorial overlay at first launch.\n",
      "[P18 [00:03:40]] Pretty intuitive overall. I’d just tweak interaction cues and maybe add a tutorial overlay at first launch.\n",
      "[P16 [00:03:59]] Pretty intuitive overall. I’d just tweak interaction cues and maybe add a tutorial overlay at first launch.\n",
      "\n",
      "--- Sample quotes from Cluster 5 ---\n",
      "[P01 [00:03:08]] No lag, though the ambient sound loop is a little short—I noticed repetition after a few minutes.\n",
      "[P18 [00:03:09]] No lag, though the ambient sound loop is a little short—I noticed repetition after a few minutes.\n",
      "[P16 [00:03:18]] No lag, though the ambient sound loop is a little short—I noticed repetition after a few minutes.\n"
     ]
    }
   ],
   "source": [
    "# Show a few sample quotes per cluster\n",
    "def show_samples(df, cluster_id, n=5):\n",
    "    examples = df[df[\"cluster\"] == cluster_id].sample(min(n, (df[\"cluster\"] == cluster_id).sum()), random_state=42)\n",
    "    print(f\"\\n--- Sample quotes from Cluster {cluster_id} ---\")\n",
    "    for _, r in examples.iterrows():\n",
    "        print(f\"[{r['participant_id']} {r['time']}] {r['text']}\")\n",
    "\n",
    "for k in range(best_k):\n",
    "    show_samples(df, k, n=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
